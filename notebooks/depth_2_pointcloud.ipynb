{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Total RGB images  24\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import sys \n",
    "import torch \n",
    "from matplotlib import pyplot as plt \n",
    "from glob import glob \n",
    "import cv2 \n",
    "import open3d as o3d   \n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "from utils.load_tof_images import create_from_zip_absolute  as load_assignment_data\n",
    "from depth_model import inference as infer\n",
    "\n",
    "id = \"253ebd40-1ddd-11ed-8dde-f768ee859a71\"\n",
    "path = \"../data/360_scans/\"+id\n",
    "rgb_files = glob(path+\"/rgb/*\")\n",
    "print(\"Total RGB images \",len(rgb_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/360_scans/253ebd40-1ddd-11ed-8dde-f768ee859a71/rgb/22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f145f5704c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_fpath = rgb_files[np.random.randint(0,len(rgb_files))]\n",
    "print(rgb_fpath)\n",
    "depth_fpath = rgb_fpath.replace('rgb','depth')\n",
    "calib_fpath = os.path.dirname(rgb_fpath).replace('rgb','calibration/0')\n",
    "\n",
    "data = load_assignment_data(rgb_fpath=rgb_fpath,depthmap_fpath=depth_fpath,calibration_fpath=calib_fpath)\n",
    "rgb_image = data[8]\n",
    "depth_map = data[3]\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(rgb_image)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(depth_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image resolution: (240, 180)\n",
      "Data type: float64\n",
      "Min value: 0.0\n",
      "Max value: 7.412\n"
     ]
    }
   ],
   "source": [
    "# print properties:\n",
    "print(f\"Image resolution: {depth_map.shape}\")\n",
    "print(f\"Data type: {depth_map.dtype}\")\n",
    "print(f\"Min value: {np.min(depth_map)}\")\n",
    "print(f\"Max value: {np.max(depth_map)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Depth camera calibration for Asssignment dataset \n",
    "\n",
    "- The calibration matrix M is a 3Ã—3 matrix:\n",
    "\n",
    "                | fx 0   cx |\n",
    "                | 0  fy  cy |\n",
    "                | 0  0   1  |\n",
    "\n",
    "Where fx, fy and cx, cy are the focal length and the optical centers\n",
    "\n",
    "- Point cloud computing\n",
    "Computing point cloud here means transforming the depth pixel from the depth image 2D coordinate system to the depth camera 3D coordinate system (x, y and z). The 3D coordinates are computed using the following formulas, where depth(i, j) is the depth value at the row i and column j:\n",
    "            \n",
    "            | z = depth(i,j)       |\n",
    "            | x = ( (j-cx) x z)/fx |\n",
    "            | y = ( (i-cy) x z)/fy |\n",
    "            \n",
    "[Link](https://betterprogramming.pub/point-cloud-computing-from-rgb-d-images-918414d57e80) to info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth camera parameters:\n",
    "FX_DEPTH = 0.7811297\n",
    "FY_DEPTH = 1.5166936\n",
    "CX_DEPTH = 0.50329405\n",
    "CY_DEPTH = 0.5187362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize = True\n",
    "if visualize:\n",
    "    # get depth resolution:\n",
    "    height, width = depth_map.shape\n",
    "    length = height * width\n",
    "    # compute indices:\n",
    "    jj = np.tile(range(width), height)\n",
    "    ii = np.repeat(range(height), width)\n",
    "    # rechape depth image\n",
    "    z = depth_map.reshape(length)\n",
    "    # compute pcd:\n",
    "    pcd = np.dstack([(ii - CX_DEPTH) * z / FX_DEPTH,\n",
    "                    (jj - CY_DEPTH) * z / FY_DEPTH,\n",
    "                    z]).reshape((length, 3))\n",
    "\n",
    "    pcd_o3d = o3d.geometry.PointCloud()  # create point cloud object\n",
    "    pcd_o3d.points = o3d.utility.Vector3dVector(pcd)  # set pcd_np as the point cloud points\n",
    "    # Visualize:\n",
    "    o3d.visualization.draw_geometries([pcd_o3d])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Image Data from the standard script provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_assignment_data(rgb_fpath=rgb_fpath,depthmap_fpath=depth_fpath,calibration_fpath=calib_fpath)\n",
    "rgb_image = data[8]\n",
    "depth_map = data[3]\n",
    "depth_scale = data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "2023-07-04 17:27:07.932051: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-04 17:27:07.972236: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-04 17:27:09.237502: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " predicted Depth map.. Child coordinates are [114  65 279 543]\n"
     ]
    }
   ],
   "source": [
    "child_bbox = infer.detect_child(rgb_image)\n",
    "\n",
    "predicted_image = infer.inference_rgbimage(rgb_image=rgb_image,depth_image_size=rgb_image.shape[:2])\n",
    "\n",
    "print(\"\\n predicted Depth map.. Child coordinates are {}\".format(child_bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image resolution: (640, 480)\n",
      "Data type: float32\n",
      "Min value: 3.4509356021881104\n",
      "Max value: 12.22368049621582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print properties:\n",
    "print(f\"Image resolution: {predicted_image.shape}\")\n",
    "print(f\"Data type: {predicted_image.dtype}\")\n",
    "print(f\"Min value: {np.min(predicted_image)}\")\n",
    "print(f\"Max value: {np.max(predicted_image)}\")\n",
    "# predicted_image = DepthNorm(predicted_image,100)\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f13f6f0ec80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(17,19))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"RGB Image\")\n",
    "plt.imshow(rgb_image)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Depth Image\")\n",
    "plt.imshow(data[3],cmap='gray')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Predicted Depth Image\")\n",
    "plt.imshow(predicted_image,cmap='gray')\n",
    "\n",
    "# depth_instensity = np.array(255*predicted_image/0x0fff,# / 0x0fff,\n",
    "#                             dtype=np.int8)\n",
    "# iio.imwrite('grayscale.png', depth_instensity)\n",
    "\n",
    "# success, encoded_image = cv2.imencode('.png', resize)\n",
    "# encoded_image.tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get depth resolution:\n",
    "height, width = predicted_image.shape\n",
    "length = height * width\n",
    "\n",
    "# compute indices:\n",
    "jj = np.tile(range(width), height)\n",
    "ii = np.repeat(range(height), width)\n",
    "\n",
    "# reshape depth image\n",
    "z = predicted_image.reshape(length)\n",
    "\n",
    "# compute pcd:\n",
    "pcd = np.dstack([(ii - CX_DEPTH) * z / FX_DEPTH,\n",
    "                 (jj - CY_DEPTH) * z / FY_DEPTH,\n",
    "                 z]).reshape((length, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_coord_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=5, origin=[0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: X11: The DISPLAY environment variable is missing\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Failed to initialize GLFW\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "pcd_o3d = o3d.geometry.PointCloud()  # create point cloud object\n",
    "pcd_o3d.points = o3d.utility.Vector3dVector(pcd)  # set pcd_np as the point cloud points\n",
    "\n",
    "# Visualize:\n",
    "o3d.visualization.draw_geometries([pcd_o3d,mesh_coord_frame])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Points with Minimum  and max values at each axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     4126.1      976.29      6.9688] [    -7.6275      3601.9      11.838] [    -7.8759      1027.4      12.224]\n",
      "[    -7.8759      1027.4      12.224] [     -6.887     -3.6558      10.689] [     351.21      510.76      3.4509]\n"
     ]
    }
   ],
   "source": [
    "x_max = max(pcd_o3d.points,key=lambda x: x[0])\n",
    "y_max = max(pcd_o3d.points,key=lambda x: x[1])\n",
    "z_max = max(pcd_o3d.points,key=lambda x: x[2])\n",
    "\n",
    "x_min = min(pcd_o3d.points,key=lambda x: x[0])\n",
    "y_min = min(pcd_o3d.points,key=lambda x: x[1])\n",
    "z_min = min(pcd_o3d.points,key=lambda x: x[2])\n",
    "\n",
    "print(x_max,y_max,z_max)\n",
    "print(x_min,y_min,z_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[     302.17,      1001.5,      5.5542],\n",
       "       [     301.88,      1004.2,      5.5488],\n",
       "       [     301.57,      1006.8,      5.5432],\n",
       "       ...,\n",
       "       [     3273.3,      1284.7,       7.073],\n",
       "       [       3268,      1287.3,      7.0615],\n",
       "       [     3262.9,      1289.9,      7.0504]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 65*320+114\n",
    "b = 543*320+279\n",
    "print(b) \n",
    "# 114  65 279 543\n",
    "np.asarray(pcd_o3d.points)[20914:174039]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

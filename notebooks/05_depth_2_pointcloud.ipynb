{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Total RGB images  26\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import sys \n",
    "import torch \n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt \n",
    "from glob import glob \n",
    "import cv2 \n",
    "import open3d as o3d   \n",
    "import gc\n",
    "import math\n",
    "\n",
    "matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "from utils.load_tof_images import create_from_zip_absolute  as load_assignment_data\n",
    "from depth_model import inference as infer\n",
    "\n",
    "id = \"6295be80-2857-11ed-8783-4b26e63c0e02\"\n",
    "path = \"../data/360_scan/\"+id\n",
    "rgb_files = glob(path+\"/rgb/*\")\n",
    "print(\"Total RGB images \",len(rgb_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/360_scan/6295be80-2857-11ed-8783-4b26e63c0e02/rgb/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efbd5a3fd60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_fpath = rgb_files[np.random.randint(0,len(rgb_files))]\n",
    "print(rgb_fpath)\n",
    "depth_fpath = rgb_fpath.replace('rgb','depth')\n",
    "calib_fpath = os.path.dirname(rgb_fpath).replace('rgb','calibration/0')\n",
    "\n",
    "data = load_assignment_data(rgb_fpath=rgb_fpath,depthmap_fpath=depth_fpath,calibration_fpath=calib_fpath)\n",
    "rgb_image = data[8]\n",
    "depth_map = data[3]\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(rgb_image)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(depth_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image resolution: (240, 180)\n",
      "Data type: float64\n",
      "Min value: 0.0\n",
      "Max value: 1.819\n"
     ]
    }
   ],
   "source": [
    "# print properties:\n",
    "print(f\"Image resolution: {depth_map.shape}\")\n",
    "print(f\"Data type: {depth_map.dtype}\")\n",
    "print(f\"Min value: {np.min(depth_map)}\")\n",
    "print(f\"Max value: {np.max(depth_map)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Depth camera calibration for Asssignment dataset \n",
    "\n",
    "- The calibration matrix M is a 3Ã—3 matrix:\n",
    "\n",
    "                | fx 0   cx |\n",
    "                | 0  fy  cy |\n",
    "                | 0  0   1  |\n",
    "\n",
    "Where fx, fy and cx, cy are the focal length and the optical centers\n",
    "\n",
    "- Point cloud computing\n",
    "\n",
    "    Computing point cloud here means transforming the depth pixel from the depth image 2D coordinate system to the depth camera 3D coordinate system (x, y and z). The 3D coordinates are computed using the following formulas, where depth(i, j) is the depth value at the row i and column j:\n",
    "            \n",
    "            | z = depth(i,j)       |\n",
    "            | x = ( (j-cx) x z)/fx |\n",
    "            | y = ( (i-cy) x z)/fy |\n",
    "            \n",
    "[Link](https://betterprogramming.pub/point-cloud-computing-from-rgb-d-images-918414d57e80) to info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth camera parameters:\n",
    "FX_DEPTH = 0.7811297\n",
    "FY_DEPTH = 1.5166936\n",
    "CX_DEPTH = 0.50329405\n",
    "CY_DEPTH = 0.5187362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize = False\n",
    "if visualize:\n",
    "    # get depth resolution:\n",
    "    height, width = depth_map.shape\n",
    "    length = height * width\n",
    "    # compute indices:\n",
    "    jj = np.tile(range(width), height)\n",
    "    ii = np.repeat(range(height), width)\n",
    "    # rechape depth image\n",
    "    z = depth_map.reshape(length)\n",
    "    # compute pcd:\n",
    "    pcd = np.dstack([(ii - CX_DEPTH) * z / FX_DEPTH,\n",
    "                    (jj - CY_DEPTH) * z / FY_DEPTH,\n",
    "                    z]).reshape((length, 3))\n",
    "\n",
    "    pcd_o3d = o3d.geometry.PointCloud()  # create point cloud object\n",
    "    pcd_o3d.points = o3d.utility.Vector3dVector(pcd)  # set pcd_np as the point cloud points\n",
    "    # Visualize:\n",
    "    o3d.visualization.draw_geometries([pcd_o3d])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Image Data from the standard script provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 480, 3)\n",
      "(240, 180)\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "data = load_assignment_data(rgb_fpath=rgb_fpath,depthmap_fpath=depth_fpath,calibration_fpath=calib_fpath)\n",
    "rgb_image = data[8]\n",
    "depth_map = data[3]\n",
    "depth_scale = data[4]\n",
    "\n",
    "print(rgb_image.shape)\n",
    "print(depth_map.shape)\n",
    "print(depth_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samartht/anaconda3/envs/pydepth/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "child_bbox = infer.detect_child(rgb_image)\n",
    "x1,y1,x2,y2 = child_bbox\n",
    "\n",
    "predicted_image = infer.inference_rgbimage(rgb_image=rgb_image[y1:y2,x1:x2],depth_image_size=depth_map.shape[:2])\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# print(\"\\n predicted Depth map.. Child coordinates are {}\".format(child_bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image resolution: (240, 180)\n",
      "Data type: float32\n",
      "Min value: 3.223318099975586\n",
      "Max value: 11.395037651062012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print properties:\n",
    "print(f\"Image resolution: {predicted_image.shape}\")\n",
    "print(f\"Data type: {predicted_image.dtype}\")\n",
    "print(f\"Min value: {np.min(predicted_image)}\")\n",
    "print(f\"Max value: {np.max(predicted_image)}\")\n",
    "# predicted_image = DepthNorm(predicted_image,100)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_961/1150515325.py:13: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(17,19))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"RGB Image\")\n",
    "plt.imshow(rgb_image)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Depth Image\")\n",
    "plt.imshow(data[3],cmap='gray')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Predicted Depth Image\")\n",
    "plt.imshow(predicted_image,cmap='gray')\n",
    "plt.show()\n",
    "# depth_instensity = np.array(255*predicted_image/0x0fff,# / 0x0fff,\n",
    "#                             dtype=np.int8)\n",
    "# iio.imwrite('grayscale.png', depth_instensity)\n",
    "\n",
    "# success, encoded_image = cv2.imencode('.png', resize)\n",
    "# encoded_image.tobytes()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create Point Cloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point Cloud shape  (43200, 3)\n"
     ]
    }
   ],
   "source": [
    "# Colors:\n",
    "RED = [1., 0., 0.]\n",
    "GREEN = [0., 1., 0.]\n",
    "BLUE = [0., 0., 1.]\n",
    "YELLOW = [1., 1., 0.]\n",
    "MAGENTA = [1., 0., 1.]\n",
    "CYAN = [0., 1., 1.]\n",
    "\n",
    "# get depth resolution:\n",
    "colors = [RED, GREEN, BLUE, MAGENTA, YELLOW, CYAN]\n",
    "height, width = predicted_image.shape\n",
    "length = height * width\n",
    "\n",
    "# compute indices:\n",
    "jj = np.tile(range(width), height)\n",
    "ii = np.repeat(range(height), width)\n",
    "\n",
    "# reshape depth image\n",
    "z = predicted_image.reshape(length)\n",
    "\n",
    "# compute pcd:\n",
    "pcd = np.dstack([(ii - CX_DEPTH) * z / FX_DEPTH,\n",
    "                 (jj - CY_DEPTH) * z / FY_DEPTH,\n",
    "                 z]).reshape((length, 3))\n",
    "print(\"Point Cloud shape \",pcd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = o3d.geometry.TriangleMesh.create_coordinate_frame()\n",
    "pcd_o3d = o3d.geometry.PointCloud()\n",
    "# create point cloud object\n",
    "pcd_o3d.points = o3d.utility.Vector3dVector(pcd)  # set pcd_np as the point cloud points\n",
    "pcd_o3d.estimate_normals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize:\n",
    "# if visualize:\n",
    "o3d.visualization.draw_geometries([pcd_o3d,axes])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Points with Minimum  and max values at each axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_max = max(pcd_o3d.points,key=lambda x: x[0])\n",
    "y_max = max(pcd_o3d.points,key=lambda x: x[1])\n",
    "z_max = max(pcd_o3d.points,key=lambda x: x[2])\n",
    "\n",
    "x_min = min(pcd_o3d.points,key=lambda x: x[0])\n",
    "y_min = min(pcd_o3d.points,key=lambda x: x[1])\n",
    "z_min = min(pcd_o3d.points,key=lambda x: x[2])\n",
    "positions = [x_max, y_max, z_max, x_min, y_min, z_min]\n",
    "\n",
    "sphere = o3d.geometry.TriangleMesh.create_sphere()\n",
    "geometries = [pcd_o3d, sphere]\n",
    "\n",
    "for i in range(len(positions)):\n",
    "    sphere.translate(np.asarray(positions[i]))\n",
    "    # add color:\n",
    "    sphere.paint_uniform_color(np.asarray(colors[i]))\n",
    "    # compute normals for vertices or faces:\n",
    "    sphere.compute_vertex_normals()\n",
    "    # add to geometry list to display later:\n",
    "    geometries.append(sphere)\n",
    "\n",
    "o3d.visualization.draw_geometries(geometries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = math.sqrt(z_max[2]**2 - z_min[2]**2)\n",
    "round(height*10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcdchild_o3d = o3d.geometry.PointCloud()\n",
    "# pcdchild_o3d.points = o3d.utility.Vector3dVector(data) \n",
    "# pcdchild_o3d.estimate_normals()\n",
    "# o3d.visualization.draw_geometries([pcdchild_o3d,axes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "import matplotlib \n",
    "from glob import glob \n",
    "import open3d as o3d   \n",
    "import math\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total RGB images  26\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"../src/\")\n",
    "from utils.load_tof_images import create_from_zip_absolute  as load_assignment_data\n",
    "from depth_model import inference as infer\n",
    "\n",
    "id = \"6295be80-2857-11ed-8783-4b26e63c0e02\"  # Change the id to get the other values \n",
    "path = \"../data/360_scan/\"+id\n",
    "rgb_files = glob(path+\"/rgb/*\")\n",
    "print(\"Total RGB images \",len(rgb_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth camera parameters:\n",
    "FY_DEPTH = 0.7811297\n",
    "FX_DEPTH = 1.5166936\n",
    "CY_DEPTH = 0.50329405\n",
    "CX_DEPTH = 0.5187362\n",
    "\n",
    "\n",
    "def get_image_data(rgb_fpath):\n",
    "    depth_fpath = rgb_fpath.replace('rgb','depth')\n",
    "    calib_fpath = os.path.dirname(rgb_fpath).replace('rgb','calibration/0')\n",
    "    data = load_assignment_data(rgb_fpath=rgb_fpath,depthmap_fpath=depth_fpath,calibration_fpath=calib_fpath)\n",
    "    return data[8],data[3],data[4]\n",
    "\n",
    "\n",
    "def create_point_cloud(predicted_image):\n",
    "    # get depth resolution:\n",
    "    height, width = predicted_image.shape\n",
    "    length = height * width\n",
    "\n",
    "    # compute indices:\n",
    "    jj = np.tile(range(width), height)\n",
    "    ii = np.repeat(range(height), width)\n",
    "\n",
    "    # reshape depth image\n",
    "    z = predicted_image.reshape(length)\n",
    "    \n",
    "    # compute pcd:\n",
    "    pcd = np.dstack([(ii - CX_DEPTH) * z / FX_DEPTH,\n",
    "                    (jj - CY_DEPTH) * z / FY_DEPTH,\n",
    "                    z]).reshape((length, 3))\n",
    "    # print(\"Point Cloud shape \",pcd.shape)\n",
    "    return pcd\n",
    "\n",
    "def get_approx_height(pcd_points):\n",
    "    x_max = max(pcd_points.points,key=lambda x: x[0])\n",
    "    y_max = max(pcd_points.points,key=lambda x: x[1])\n",
    "    z_max = max(pcd_points.points,key=lambda x: x[2])\n",
    "\n",
    "    x_min = min(pcd_points.points,key=lambda x: x[0])\n",
    "    y_min = min(pcd_points.points,key=lambda x: x[1])\n",
    "    z_min = min(pcd_points.points,key=lambda x: x[2])\n",
    "    \n",
    "    height = math.sqrt(z_max[2]**2 - z_min[2]**2)\n",
    "\n",
    "    return round(height*10,1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:21<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from  tqdm import tqdm\n",
    "heights = []\n",
    "for fname in tqdm(rgb_files,total=len(rgb_files)):\n",
    "    rgb ,  depth , scale = get_image_data(fname)\n",
    "    child_bbox = infer.detect_child(rgb)\n",
    "    x1,y1,x2,y2 = child_bbox\n",
    "    \n",
    "    predicted_image = infer.inference_rgbimage(rgb_image=rgb[y1:y2,x1-20:x2+20],\n",
    "                                               depth_image_size=depth.shape[:2],\n",
    "                                               )\n",
    "    \n",
    "    pcd = create_point_cloud(predicted_image=predicted_image)\n",
    "    pcd_o3d = o3d.geometry.PointCloud()  # create point cloud object\n",
    "    pcd_o3d.points = o3d.utility.Vector3dVector(pcd)  # set pcd_np as the point cloud points\n",
    "    pcd_o3d.estimate_normals()\n",
    "    heights.append(get_approx_height(pcd_o3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Height of the child 117.64\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Height of the child {:.2f}\".format(np.mean(heights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydepth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
